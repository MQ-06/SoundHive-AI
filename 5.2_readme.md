## 2. Dataset Description

Dataset name & source: temperature_cleaned.csv, processed sensor data from SoundHive-AI project.

Data type: Time-series, numeric (temperature).

Number of instances: 401,786 rows, 2 columns (timestamp, temperature).

Target variable: label — 3-class labels derived from quartiles of the mean temperature for each 1-hour window:

0 → Low temperature (< 25th percentile)

1 → Medium temperature (25th–75th percentile)

2 → High temperature (> 75th percentile)

Metadata: Temperature readings in °C, recorded every few minutes. Dataset cleaned for missing values and duplicates in the previous preprocessing step.

Dataset quality considerations:

Missing values handled via interpolation

Duplicates removed

Outliers checked during preprocessing

Classes are reasonably balanced (label counts: 0=2184, 1=4369, 2=2184).

## 3. Feature Engineering / Preprocessing

Resampling / Windowing:

Time-series resampled into 1-hour windows.

Feature extraction per window:

count → number of readings

mean, std, min, max, median → basic statistics

range → max - min

first, last → first and last temperature readings

diff → last - first (change in temperature)

skew → distribution shape of temperature

hour → hour of the day

hour_sin & hour_cos → cyclical encoding for hour

weekday → day of the week

Label creation:

Derived 3-class labels (0, 1, 2) from quartiles of temp_mean.

Train/Test Split:

80/20 split with stratification to preserve label distribution.

Features scaled using StandardScaler for models sensitive to magnitude (LR, SVM).

## 4. Models / Classifiers

Classical ML models implemented as baseline:

Logistic Regression (LR)

Support Vector Machine (SVM, RBF kernel)

Decision Tree (DT)

Random Forest (RF, n_estimators=100)

Gradient Boosting (GB, n_estimators=100)

Random seed fixed (RANDOM_STATE=42) for reproducibility.

Default hyperparameters used; RF feature importances extracted.

## 5. Evaluation Setup

Metrics: Accuracy, Precision (macro), Recall (macro), F1-score (macro), Confusion Matrix.

Scaling: Only applied to LR and SVM. Tree-based models used raw features.

## 6. Results
Model	Accuracy	Precision (macro)	Recall (macro)	F1-score (macro)
LogisticRegression	0.9846	0.9855	0.9836	0.9845
SVM-RBF	0.9788	0.9784	0.9794	0.9788
DecisionTree	1.0000	1.0000	1.0000	1.0000
RandomForest	1.0000	1.0000	1.0000	1.0000
GradientBoosting	1.0000	1.0000	1.0000	1.0000

Confusion matrices show that the models classified nearly all samples correctly.

Random Forest feature importances saved for reference.



T